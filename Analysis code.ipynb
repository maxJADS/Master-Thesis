{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code for analysis of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### includes dashboard, evaluation, parameter k tuning, and validation with labeled change point conbined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.fft import rfft, rfftfreq, rfft, irfft, fftfreq, fft\n",
    "import scipy\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import plotly.express as px\n",
    "import plotly.subplots as ps\n",
    "import dash_core_components as dcc\n",
    "# from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(path1, name1, index1, path2, name2, index2):\n",
    "    \"\"\"load two specified datasets and paste the second directly after the first\n",
    "    after for each subtracting the mean and dividing by the standard deviation\"\"\"\n",
    "    \n",
    "    df1 = pd.read_excel(path1)[index1[0]:index1[1]].reset_index()\n",
    "    df2 = pd.read_excel(path2)[index2[0]:index2[1]].reset_index()\n",
    "    \n",
    "    sig1 = df1.Temp\n",
    "    sig2 = df2.Temp\n",
    "    N=12*24\n",
    "    win_day = scipy.signal.windows.tukey(M=N, alpha=0.5, sym=False)\n",
    "    df1['avg'] = scipy.signal.convolve(sig1, win_day, mode='same') / sum(win_day)\n",
    "    df2['avg'] = scipy.signal.convolve(sig2, win_day, mode='same') / sum(win_day)\n",
    "    df1['std'] = df1['Temp'].rolling(N, min_periods=1).std()\n",
    "    df1['std'][0] = 1\n",
    "    df2['std'] = df2['Temp'].rolling(N, min_periods=1).std()\n",
    "    df2['std'][0] = 1\n",
    "    \n",
    "    df1['temp-avg'] = df1['Temp']-df1['avg']\n",
    "    df2['temp-avg'] = df2['Temp']-df2['avg']\n",
    "    \n",
    "    df1['temp-avg/std'] = df1['temp-avg']/df1['std']\n",
    "    df2['temp-avg/std'] = df2['temp-avg']/df2['std']\n",
    "\n",
    "    df1 = df1.iloc[1000:-1000]\n",
    "    df2 = df2.iloc[1000:-1000]\n",
    "    \n",
    "    df3 = pd.concat([df1, df2], ignore_index=True)\n",
    "    df4 = df3[['EventDt', 'temp-avg/std']].rename(columns = {'temp-avg/std':'Temp'})\n",
    "    \n",
    "    df4['EventDt'] = pd.date_range(str(df4['EventDt'][0]), periods=len(df4), freq='5T')\n",
    "    \n",
    "    df4['Switch'] = 0\n",
    "    df4['Switch'][len(df1)-1] = 1\n",
    "    \n",
    "    df4.to_excel('01 - Raw Data/combinations/random combinations/data_{}_{}.xlsx'.format(name1, name2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutions(data):\n",
    "    \"\"\"compute convolutions of the data on different timescales\n",
    "    based on a Tukey window convolutions of lengths of a week/day/hour\"\"\"\n",
    "    \n",
    "    sig = data.Temp\n",
    "    win_week = scipy.signal.windows.tukey(M=12*24*7, alpha=0.5, sym=False)\n",
    "    data['gauss_1week'] = scipy.signal.convolve(sig, win_week, mode='same') / sum(win_week)\n",
    "    win_day = scipy.signal.windows.tukey(M=12*24, alpha=0.5, sym=False)\n",
    "    data['gauss_1day'] = scipy.signal.convolve(sig, win_day, mode='same') / sum(win_day)\n",
    "    win_hour = scipy.signal.windows.tukey(M=12, alpha=0.5, sym=False)\n",
    "    data['gauss_1hour'] = scipy.signal.convolve(sig, win_hour, mode='same') / sum(win_hour)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxstd(data, N):\n",
    "    \"\"\"compute the minimum and maximum temperatures, and standard deviation\n",
    "    with a rolling window of specified length\"\"\"\n",
    "    \n",
    "    data['max Temp'] = data['Temp'].rolling(N, min_periods=1).max()\n",
    "    data['min Temp']  = data['Temp'].rolling(N, min_periods=1).min()\n",
    "    data['std Temp'] = data['Temp'].rolling(N, min_periods=1).std()\n",
    "    data['std Temp'][0] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(data, lower, upper):\n",
    "    \"\"\"filter outliers based on a lower and upper percentile of the 1hour convoluted data\"\"\"\n",
    "    \n",
    "    data = data[data['gauss_1hour']<np.percentile(data['gauss_1hour'], upper)]\n",
    "    data = data[data['gauss_1hour']>np.percentile(data['gauss_1hour'], lower)]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### spectral analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectrogram(df, N):\n",
    "    \"\"\"computes the spectrogram of the temperature signal\"\"\"\n",
    "    \n",
    "    f, t, Sxx = scipy.signal.spectrogram(df['Temp - avg'], fs=1/300,  nperseg=N)\n",
    "    \n",
    "    return f, t, Sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octave_intensities(N, f, t, Sxx):\n",
    "    \"\"\"computes the absolute and relative octave intensities based on the spectrogram\"\"\"\n",
    "    \n",
    "    delta_t = 5*60\n",
    "    T = N*delta_t\n",
    "    delta_f = 1/T\n",
    "    F = N*delta_f/2\n",
    "    M = int(round(np.log(F/delta_f)))\n",
    "    \n",
    "    parts = M\n",
    "    borders = [(delta_f*math.exp((i/M)*np.log(F/delta_f))) for i in range(M+1)]\n",
    "    indi = [len(f[f<=borders[i]]) for i in range(len(borders))]\n",
    "    metrics_relative = dict()\n",
    "    metrics = dict()\n",
    "    for d in range(len(t)):\n",
    "        tindex = t[d]\n",
    "        F = [Sxx[i][d] for i in range(len(Sxx))]\n",
    "        metrics[t[d]] = dict()\n",
    "        metrics_relative[t[d]] = dict()\n",
    "        sumf = sum(F[:])\n",
    "        for b in range(1, parts+1):\n",
    "            metrics_relative[t[d]][b] = sum(F[indi[b-1]:indi[b]])/sumf\n",
    "            metrics[t[d]][b] = sum(F[indi[b-1]:indi[b]])\n",
    "            \n",
    "    return metrics, metrics_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_spectrum(N, intensities):\n",
    "    \"\"\"computes the entropy/Kullback-Leibner divergence/information gain based on the octave intensities\"\"\"\n",
    "    \n",
    "    delta_t = 5*60\n",
    "    T = N*delta_t \n",
    "    delta_f = 1/T\n",
    "    F = N*delta_f/2\n",
    "    M = int(round(np.log(F/delta_f)))\n",
    "    \n",
    "    Poct = intensities\n",
    "    Qpinkyoct = 1/M\n",
    "    KL = dict()\n",
    "    for i in Poct:\n",
    "        KL[i] = sum([Poct[i][j]/Qpinkyoct for j in range(1,M+1)])\n",
    "    \n",
    "    return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_intensities(intensities):\n",
    "    \"\"\"computes the first two principal components of the octave intensities\"\"\"\n",
    "    \n",
    "    metrics = intensities\n",
    "    df_metrics = pd.DataFrame(metrics).T\n",
    "    \n",
    "    df = df_metrics.rename({1: 'octave 1', \n",
    "                            2: 'octave 2', \n",
    "                            3: 'octave 3',\n",
    "                            4: 'octave 4',\n",
    "                            5: 'octave 5'}, axis=1)\n",
    "    features = df.columns\n",
    "\n",
    "    pca = PCA(2)\n",
    "    components = pca.fit_transform(df[features])\n",
    "    labels = {str(i): f\"PC {i+1} ({var:.1f}%)\" for i, var in enumerate(pca.explained_variance_ratio_ * 100)}\n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning_additive(df, name, period, l, h, k):\n",
    "    \"\"\"computes warnings based on threshold values \n",
    "    computed with percentile values calculated over a specified period and a factor k in an additive formula\n",
    "    \"\"\"\n",
    "    \n",
    "    warnings = list()\n",
    "    skip = period\n",
    "    values = list()\n",
    "    calculate = 1\n",
    "    for value in df[name]:\n",
    "        if skip !=0:\n",
    "            warnings.append(np.nan)\n",
    "            values.append(value)\n",
    "            skip -= 1\n",
    "            continue\n",
    "        elif skip == 0:\n",
    "            calculate -= 1\n",
    "            if calculate == 0:\n",
    "                l_percentile = np.percentile(values, l)\n",
    "                h_percentile = np.percentile(values, h)\n",
    "                median = np.median(values)\n",
    "                low = median+k*(l_percentile-median)\n",
    "                high = median+k*(h_percentile-median)\n",
    "            if value > high:\n",
    "                warnings.append(1)\n",
    "                skip = period\n",
    "                calculate = 1   \n",
    "            elif value < low:\n",
    "                warnings.append(-1)\n",
    "                skip = period\n",
    "                calculate = 1\n",
    "            else:\n",
    "                warnings.append(0)\n",
    "                \n",
    "    return warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning_multiplicative(df, name, period, l, h, k):\n",
    "    \"\"\"computes warnings based on threshold values \n",
    "    computed with percentile values calculated over a specified period and a factor k in a multiplicative formula\n",
    "    \"\"\"\n",
    "    \n",
    "    warnings = list()\n",
    "    skip = period\n",
    "    values = list()\n",
    "    calculate = 1\n",
    "    for value in df[name]:\n",
    "        if skip !=0:\n",
    "            warnings.append(np.nan)\n",
    "            values.append(value)\n",
    "            skip -= 1\n",
    "            continue\n",
    "        elif skip == 0:\n",
    "            calculate -= 1\n",
    "            if calculate == 0:\n",
    "                l_percentile = np.percentile(values, l)\n",
    "                h_percentile = np.percentile(values, h)\n",
    "                median = np.median(values) # kan weg\n",
    "                low = (l_percentile/median)/k*median\n",
    "                high = (h_percentile/median)*k*median\n",
    "            if value > high:\n",
    "                warnings.append(1)\n",
    "                skip = period\n",
    "                calculate = 1\n",
    "            elif value < low:\n",
    "                warnings.append(-1)\n",
    "                skip = period\n",
    "                calculate = 1\n",
    "            else:\n",
    "                warnings.append(0)\n",
    "                \n",
    "    return warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(df, dfmm, dfc, lines, dfKL, components, t_dates, l, h, k_list):\n",
    "    \"\"\"uses the additive and multiplicative warning functions to copmute warnings for all performance indicators\"\"\"\n",
    "    \n",
    "    df['warnings_temp'] = warning_additive(df=df, name='Temp', period=12*24*31, l=l, h=h, k=k_list[0])\n",
    "    \n",
    "    ts = ' Temp'\n",
    "    for column in ['min', 'max']:\n",
    "        dfmm['warnings_{}'.format(column)] = warning_additive(df=dfmm, name=column+ts, period=12*24*31, l=l, h=h, k=k_list[1])\n",
    "    for column in ['std']:\n",
    "        dfmm['warnings_{}'.format(column)] = warning_multiplicative(df=dfmm, name=column+ts, period=12*24*31, l=l, h=h, k=k_list[3])\n",
    "    \n",
    "    dfc['warnings_avg'] = warning_additive(df=dfc, name='gauss_1day', period=12*24*31, l=l, h=h, k=k_list[2])\n",
    "    \n",
    "    dfl = pd.DataFrame(lines)\n",
    "    for column in dfl:\n",
    "        dfl['warnings_oct{}'.format(column)] = warning_multiplicative(df=dfl, name=column, period=31, l=l, h=h, k=k_list[4])\n",
    "        \n",
    "    dfKL['warnings_IG'] = warning_multiplicative(df=dfKL, name=1, period=31, l=l, h=h, k=k_list[5])\n",
    "    \n",
    "    dfpca = pd.DataFrame(components)\n",
    "    for column in dfpca:\n",
    "        dfpca['warnings_PC{}'.format(column)] = warning_additive(df=dfpca, name=column, period=31, l=l, h=h, k=k_list[6])\n",
    "        \n",
    "    return df, dfmm, dfc, dfl, dfKL, dfpca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### count warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warnings_stats(dfT, dfMMS, dfAVG, dfO, dfIG, dfPC):\n",
    "    \"\"\"creates a dataframe with counts of all warnings for all performance indicators, \n",
    "    the average warnings per year for each performance indicator,\n",
    "    and the average divided by the amount of variables the performance indicator consists of\"\"\"\n",
    "    \n",
    "    years = len(dfIG)/365\n",
    "    k = pd.DataFrame(index=['Total warnings', 'Average per year', 'Average divided by amount of variables'],\n",
    "                     columns=['Temperature', 'Min/Max temperature', 'Average temperature', 'Temperature SD',\n",
    "                              'Octave intensities', 'Information gain', 'Principal components'])\n",
    "    \n",
    "    k['Temperature']['Total warnings'] = dfT['warnings_temp'].abs().sum()\n",
    "    k['Temperature']['Average per year'] = k['Temperature']['Total warnings']/years\n",
    "    k['Temperature']['Average divided by amount of variables'] = k['Temperature']['Average per year']\n",
    "    \n",
    "    k['Min/Max temperature']['Total warnings'] = dfMMS[['warnings_min', 'warnings_max']].abs().sum().sum()\n",
    "    k['Min/Max temperature']['Average per year'] = k['Min/Max temperature']['Total warnings']/years\n",
    "    k['Min/Max temperature']['Average divided by amount of variables'] = k['Min/Max temperature']['Average per year']/2\n",
    "    \n",
    "    k['Average temperature']['Total warnings'] = dfAVG['warnings_avg'].abs().sum()\n",
    "    k['Average temperature']['Average per year'] = k['Average temperature']['Total warnings']/years\n",
    "    k['Average temperature']['Average divided by amount of variables'] = k['Average temperature']['Average per year']\n",
    "    \n",
    "    k['Temperature SD']['Total warnings'] = dfMMS['warnings_std'].abs().sum()\n",
    "    k['Temperature SD']['Average per year'] = k['Temperature SD']['Total warnings']/years\n",
    "    k['Temperature SD']['Average divided by amount of variables'] = k['Temperature SD']['Average per year']\n",
    "    \n",
    "    k['Octave intensities']['Total warnings'] = dfO[['warnings_oct1', 'warnings_oct2', 'warnings_oct3', 'warnings_oct4', 'warnings_oct5']].abs().sum().sum()\n",
    "    k['Octave intensities']['Average per year'] = k['Octave intensities']['Total warnings']/years\n",
    "    k['Octave intensities']['Average divided by amount of variables'] = k['Octave intensities']['Average per year']/5\n",
    "    \n",
    "    k['Information gain']['Total warnings'] = dfIG['warnings_IG'].abs().sum()\n",
    "    k['Information gain']['Average per year'] = k['Information gain']['Total warnings']/years\n",
    "    k['Information gain']['Average divided by amount of variables'] = k['Information gain']['Average per year']\n",
    "    \n",
    "    k['Principal components']['Total warnings'] = dfPC[['warnings_PC0', 'warnings_PC1']].abs().sum().sum()\n",
    "    k['Principal components']['Average per year'] = k['Principal components']['Total warnings']/years\n",
    "    k['Principal components']['Average divided by amount of variables'] = k['Principal components']['Average per year']/2\n",
    "    \n",
    "    return k  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### evaluation combined datasets with labeled changepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_warning(df, dfT, dfMMS, dfAVG, dfO, dfIG, dfPC, t_dates):\n",
    "    \"\"\"computes the amount of time within which a warning was raised for each performance indicator relative to a labeled changepoint\n",
    "    to be used with the labeled changepoint combined datasets\"\"\"\n",
    "    \n",
    "    day0 = list(df['EventDt'][df['Switch'] == 1])[0]\n",
    "    \n",
    "    time_till_warning = dict()\n",
    "    \n",
    "    for index, row in dfT[dfT['EventDt']>=day0][['EventDt', 'warnings_temp']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_temp']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Temperature warning'] = time\n",
    "            break\n",
    "            \n",
    "    for index, row in dfMMS[dfMMS['EventDt']>=day0][['EventDt', 'warnings_min', 'warnings_max']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_min']) == 1 or abs(row['warnings_max']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Temperature Min/Max warning'] = time\n",
    "            break\n",
    "            \n",
    "    for index, row in dfAVG[dfAVG['EventDt']>=day0][['EventDt', 'warnings_avg']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_avg']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Temperature average warning'] = time\n",
    "            break\n",
    "            \n",
    "    for index, row in dfMMS[dfMMS['EventDt']>=day0][['EventDt', 'warnings_std']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_std']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Temperature SD warning'] = time\n",
    "            break\n",
    "            \n",
    "    dfO['EventDt'] = t_dates\n",
    "    for index, row in dfO[dfO['EventDt']>=day0][['EventDt', 'warnings_oct1', 'warnings_oct2', 'warnings_oct3', 'warnings_oct4', 'warnings_oct5']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_oct1']) == 1 or abs(row['warnings_oct2']) == 1 or abs(row['warnings_oct3']) == 1 or abs(row['warnings_oct4']) == 1 or abs(row['warnings_oct5']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Octave intensities warning'] = time\n",
    "            break\n",
    "            \n",
    "    dfIG['EventDt'] = t_dates\n",
    "    for index, row in dfIG[dfIG['EventDt']>=day0][['EventDt', 'warnings_IG']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_IG']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Information gain warning'] = time\n",
    "            break\n",
    "            \n",
    "    dfPC['EventDt'] = t_dates\n",
    "    for index, row in dfPC[dfPC['EventDt']>=day0][['EventDt', 'warnings_PC0', 'warnings_PC1']].fillna(0).iterrows():\n",
    "        if abs(row['warnings_PC0']) == 1 or abs(row['warnings_PC1']) == 1:\n",
    "            time = row['EventDt'] - day0\n",
    "            time_till_warning['Principal components warning'] = time\n",
    "            break\n",
    "            \n",
    "    return time_till_warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(path, name, N, lower=0, upper=100, index=None, k_list=[1.125 for i in range(7)], save='you forgot to name'): \n",
    "    \"\"\"loads a dataset and performs the full analysis using the above specified functions\n",
    "    plots all computed performance indicators and warnings in a dashboard\"\"\"\n",
    "    \n",
    "    #load data from path and preprocess\n",
    "    df = pd.read_excel(path)\n",
    "    if index:\n",
    "        df = df[index[0]:index[1]]\n",
    "        \n",
    "    dfmm = minmaxstd(df, N)    \n",
    "    dfc = convolutions(dfmm)\n",
    "    dfc['Temp - avg'] = dfc['Temp'] - dfc['gauss_1week']\n",
    "    dfcf = filter_outliers(dfc, lower, upper)\n",
    "    \n",
    "    #\n",
    "    ###\n",
    "    #####\n",
    "    #PLOT BASIC PERFORMANCE INDICATORS\n",
    "    fig, axs = plt.subplots(15, figsize=(10,20), constrained_layout=True)\n",
    "    fig.suptitle('Analysis Dataset {}'.format(name), y=1.01)\n",
    "    \n",
    "    #plot original temperature data\n",
    "    axs[0].plot(df['EventDt'], df['Temp'], label='Temperature')\n",
    "    axs[0].set_title(\"Temperature\")\n",
    "    axs[0].set_xlabel(\"Date\")\n",
    "    axs[0].set_ylabel(\"Temperature [°C]\")\n",
    "    axs[0].legend(['Temperature'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    \n",
    "    #plot daily minimum and maximum temperature\n",
    "    axs[2].plot(dfmm['EventDt'], dfmm['max Temp'], label='max Temperature', color='red')\n",
    "    axs[2].plot(dfmm['EventDt'], dfmm['min Temp'], label='min Temperature', color= 'royalblue')\n",
    "    axs[2].set_title(\"Daily minimum and maximum temperature\")\n",
    "    axs[2].set_xlabel(\"Date\")\n",
    "    axs[2].set_ylabel(\"Temperature [°C]\")\n",
    "    axs[2].legend(['Maximum temperature', 'Minimum temperature'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    \n",
    "    #plot one day Tukey window convoluted temperature as average temperature\n",
    "    axs[4].plot(dfc['EventDt'], dfc['gauss_1day'], label='avg Temperature')\n",
    "    axs[4].set_title(\"Temperature average (1-day Tukey convolution)\")\n",
    "    axs[4].set_xlabel(\"Date\")\n",
    "    axs[4].set_ylabel(\"Temperature [°C]\")\n",
    "    axs[4].legend(['Average temperature'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    \n",
    "    #plot daily standard deviation of the temperature\n",
    "    axs[6].plot(dfmm['EventDt'], dfmm['std Temp'], label='SD')\n",
    "    axs[6].set_title(\"Daily temperature standard deviation\")\n",
    "    axs[6].set_xlabel(\"Date\")\n",
    "    axs[6].set_ylabel(\"Temperature [°C]\")\n",
    "    axs[6].legend(['Temperature SD'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    #####\n",
    "    ###\n",
    "    #\n",
    "    \n",
    "    #SPECTRAL ANALYSIS\n",
    "    f, t, Sxx = compute_spectrogram(dfcf, N)\n",
    "    \n",
    "    #create corresponding date xaxis for the spectral performance indicators\n",
    "    end_date = dfcf['EventDt'].iloc[-1]\n",
    "    start_date = dfcf['EventDt'].iloc[0]\n",
    "    timestep = (end_date - (start_date + datetime.timedelta(seconds=t[0])))/len(t)\n",
    "    xmin, xmax = axs[0].get_xlim()\n",
    "    t_dates = [start_date + timestep*i for i in range(1, len(t)+1)]\n",
    "    \n",
    "    metrics, rel = octave_intensities(N, f, t, Sxx)\n",
    "    lines = dict()\n",
    "    for i in range(1, 5+1):\n",
    "        line = list()\n",
    "        for m in metrics:\n",
    "            line.append(metrics[m][i])\n",
    "        lines[i] = line\n",
    "    KL = entropy_spectrum(N, metrics)\n",
    "    dfKL = pd.DataFrame(zip(*KL.items())).T\n",
    "    \n",
    "    #PCA\n",
    "    components = PCA_intensities(metrics)\n",
    "    \n",
    "    #\n",
    "    ###\n",
    "    #####\n",
    "    #PLOT SPECTRAL PERFORMANCE INDICATORS\n",
    "    #plot the spectrogram\n",
    "    axs[8].pcolormesh(t_dates, f, np.log10(Sxx), shading='gouraud')\n",
    "    axs[8].set_xlim((xmin,xmax))\n",
    "    axs[8].set_yscale('symlog')\n",
    "    axs[8].set_title(\"Spectrogram\")\n",
    "    axs[8].set_xlabel(\"Date\")\n",
    "    axs[8].set_ylabel(\"Frequency [Hz]\")\n",
    "    sm = plt.cm.ScalarMappable(cmap=cm.viridis, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    cbar = fig.colorbar(sm, ax=axs[8], location='right', ticks=[0,1], aspect=10)\n",
    "    cbar.ax.set_yticklabels(['Low', 'High'])\n",
    "    \n",
    "    #plot the absolute octave intensities as a heatmap line per octave\n",
    "    for i in range(1, len(lines)+1):\n",
    "        y = [i for j in range(len(lines[i]))]\n",
    "        axs[9].scatter(x=t_dates,y=y, c=cm.viridis_r(np.abs([k/max(lines[i]) if k!=0 else 0 for k in lines[i]])), edgecolor='none')\n",
    "    axs[9].set_yticks([1, 2, 3, 4, 5])\n",
    "    axs[9].set_title(\"Sum of intensities per octave\")\n",
    "    axs[9].set_xlabel(\"Date\")\n",
    "    axs[9].set_ylabel(\"Octave\")\n",
    "    sm = plt.cm.ScalarMappable(cmap=cm.viridis_r, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    cbar = fig.colorbar(sm, ax=axs[9], location='right', ticks=[0,1], aspect=10)\n",
    "    cbar.ax.set_yticklabels(['Low', 'High'])\n",
    "    \n",
    "    #plot entropy = information gain of the spectrum\n",
    "    axs[11].plot(t_dates, dfKL[1], label='KL divergence', color='g')\n",
    "    axs[11].set_title(\"Information gain\")\n",
    "    axs[11].set_xlabel(\"Date\")\n",
    "    axs[11].set_ylabel(\"Kullback-Leibner divergence\")\n",
    "    axs[11].legend(['Kullback-Leibner divergence'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                   fancybox=True, shadow=True)\n",
    "    \n",
    "    #plot first two principal components of the ocatve intensities\n",
    "    axs[13].set_prop_cycle('color',['limegreen', 'gold'])\n",
    "    axs[13].plot(t_dates, components)\n",
    "    axs[13].set_title(\"Principal components of octave intensities\")\n",
    "    axs[13].set_xlabel(\"Date\")\n",
    "    axs[13].set_ylabel(\"Principal component\")\n",
    "    axs[13].legend(['PC 1', 'PC 2'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                   fancybox=True, shadow=True)\n",
    "    #####\n",
    "    ###\n",
    "    #\n",
    "    \n",
    "    #EVALUATION (warnings)\n",
    "    dfT, dfMMS, dfAVG, dfO, dfIG, dfPC = evaluation(df, dfmm, dfc, lines, dfKL, components, t_dates, l=1, h=99, k_list=k_list)\n",
    "    \n",
    "    #\n",
    "    ###\n",
    "    #####\n",
    "    #PLOT WARNINGS (EVALUATION)\n",
    "    #plot temperature warnings\n",
    "    axs[1].plot(dfT['EventDt'], dfT['warnings_temp'])\n",
    "    axs[1].set_title(\"Temperature evaluation\")\n",
    "    axs[1].set_ylim([-1,1])\n",
    "    axs[1].axes.get_xaxis().set_visible(False)\n",
    "    axs[1].legend(['Temperature warnings'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    axs[0].get_shared_x_axes().join(axs[0], axs[1])\n",
    "    \n",
    "    #plot minimum and maximum warnings\n",
    "    axs[3].set_prop_cycle('color',['royalblue', 'red'])\n",
    "    axs[3].plot(dfMMS['EventDt'], dfMMS[['warnings_min', 'warnings_max']])\n",
    "    axs[3].set_title(\"Temperature minimum and maximum evaluation\")\n",
    "    axs[3].set_ylim([-1,1])\n",
    "    axs[3].axes.get_xaxis().set_visible(False)\n",
    "    axs[3].legend(['Minimum temperature warnings', 'Maximum temperature warnings'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    axs[2].get_shared_x_axes().join(axs[2], axs[3])\n",
    "    \n",
    "    #plot average temperature warnings\n",
    "    axs[5].plot(dfAVG['EventDt'], dfAVG['warnings_avg'])\n",
    "    axs[5].set_title(\"Temperature average evaluation\")\n",
    "    axs[5].set_ylim([-1,1])\n",
    "    axs[5].axes.get_xaxis().set_visible(False)\n",
    "    axs[5].legend(['Average temperature warnings'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    axs[4].get_shared_x_axes().join(axs[4], axs[5])\n",
    "    \n",
    "    #plot temperature standard deviation warnings\n",
    "    axs[7].plot(dfMMS['EventDt'], dfMMS['warnings_std'])\n",
    "    axs[7].set_title(\"Temperature standard deviation evaluation\")\n",
    "    axs[7].set_ylim([-1,1])\n",
    "    axs[7].axes.get_xaxis().set_visible(False)\n",
    "    axs[7].legend(['Temperature SD warnings'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=True)\n",
    "    axs[6].get_shared_x_axes().join(axs[6], axs[7])\n",
    "    \n",
    "    #plot octave intensities warnings\n",
    "    axs[10].plot(t_dates, dfO[['warnings_oct1', 'warnings_oct2', 'warnings_oct3', 'warnings_oct4', 'warnings_oct5']]) \n",
    "    axs[10].set_title(\"Octave intensities evaluation\")\n",
    "    axs[10].set_ylim([-1,1])\n",
    "    axs[10].axes.get_xaxis().set_visible(False)\n",
    "    axs[10].legend(['warnings oct1', 'warnings oct2', 'warnings oct3', 'warnings oct4', 'warnings oct5'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                   fancybox=True, shadow=True)\n",
    "    axs[9].get_shared_x_axes().join(axs[9], axs[10])\n",
    "    \n",
    "    #plot information gain warnings\n",
    "    axs[12].plot(t_dates, dfIG['warnings_IG'], color='g')\n",
    "    axs[12].set_title(\"Information gain evaluation\")\n",
    "    axs[12].set_ylim([-1,1])\n",
    "    axs[12].axes.get_xaxis().set_visible(False)\n",
    "    axs[12].legend(['Information gain warnings'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                   fancybox=True, shadow=True)\n",
    "    axs[11].get_shared_x_axes().join(axs[11], axs[12])\n",
    "    \n",
    "    #plot principal components warnings\n",
    "    axs[14].set_prop_cycle('color',['limegreen', 'gold'])\n",
    "    axs[14].plot(t_dates, dfPC[['warnings_PC0', 'warnings_PC1']])\n",
    "    axs[14].set_title(\"Principal components of octave intensities evaluation\")\n",
    "    axs[14].set_ylim([-1,1])\n",
    "    axs[14].axes.get_xaxis().set_visible(False)\n",
    "    axs[14].legend(['warnings PC1', 'warnings PC2'], loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                   fancybox=True, shadow=True)\n",
    "    axs[13].get_shared_x_axes().join(axs[13], axs[14])\n",
    "    \n",
    "    #save figure to specified path\n",
    "    fig.savefig('thesis plots/{}.png'.format(save), bbox_inches='tight')\n",
    "    #####\n",
    "    ###\n",
    "    #\n",
    "\n",
    "    #COUNT WARNINGS\n",
    "#     df_warnings = warnings_stats(dfT, dfMMS, dfAVG, dfO, dfIG, dfPC)\n",
    "#     return name, k, df_warnings\n",
    "\n",
    "    #EVALUATION LABELED CHANGEPOINT DATASETS\n",
    "#     time_till_warning = days_warning(df, dfT, dfMMS, dfAVG, dfO, dfIG, dfPC, t_dates)\n",
    "#     return time_till_warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### example code: run to get dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_data('01 - Raw Data/data_G.xlsx', 'G', lower=5, upper=70, N=(12*24), k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using \"COUNT WARNINGS\" to get a table of warnigns per performance indicator per value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings_dict_k125 = dict()\n",
    "for i in [x for x in range(1,21) if x not in [2, 12, 13]]:\n",
    "    for k in [(9/8)**n for n in range(1,11)]:\n",
    "        path = '01 - Raw Data/Delivery 2 (enkel koelkast)/data_{}.xlsx'.format(i)\n",
    "        warnings_dict_k125['warnings_ds{}_k={}'.format(i, round(k, 3))] = analyze_data(path, name='{}'.format(i), lower=5, upper=70, N=(12*24), k=k)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_dict = dict()\n",
    "for k in [round((9/8)**n, 2) for n in range(1,11)]:\n",
    "    k_dict['k = {}'.format(k)] = dict()\n",
    "    tables_k = [warnings_dict_k125['warnings_ds{}_k={}'.format(i, k)][2] for i in [x for x in range(1,21) if x not in [2, 12, 13]]]\n",
    "    l1 = list()\n",
    "    l2 = list()\n",
    "    l3 = list()\n",
    "    l4 = list()\n",
    "    l5 = list()\n",
    "    l6 = list()\n",
    "    l7 = list()\n",
    "    for t in tables_k:\n",
    "        l1.append(t['Temperature'].loc['Average per year'])\n",
    "        l2.append(t['Min/Max temperature'].loc['Average per year'])\n",
    "        l3.append(t['Average temperature'].loc['Average per year'])\n",
    "        l4.append(t['Temperature SD'].loc['Average per year'])\n",
    "        l5.append(t['Octave intensities'].loc['Average per year'])\n",
    "        l6.append(t['Information gain'].loc['Average per year'])\n",
    "        l7.append(t['Principal components'].loc['Average per year'])   \n",
    "    k_dict['k = {}'.format(k)]['Temperature'] = sum(l1)/len(l1)\n",
    "    k_dict['k = {}'.format(k)]['Min/Max temperature'] = sum(l2)/len(l2)\n",
    "    k_dict['k = {}'.format(k)]['Average temperature'] = sum(l3)/len(l3)\n",
    "    k_dict['k = {}'.format(k)]['Temperature SD'] = sum(l4)/len(l4)\n",
    "    k_dict['k = {}'.format(k)]['Octave intensities'] = sum(l5)/len(l5)\n",
    "    k_dict['k = {}'.format(k)]['Information gain'] = sum(l6)/len(l6)\n",
    "    k_dict['k = {}'.format(k)]['Principal components'] = sum(l7)/len(l7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [round((9/8)**n, 2) for n in range(1,11)]:\n",
    "    tables_k = [warnings_dict_k125['warnings_ds{}_k={}'.format(i, k)][2] for i in [x for x in range(1,21) if x not in [2, 12, 13]]]\n",
    "    avgw_list = list() \n",
    "    for t in tables_k:\n",
    "        avg_warnings = t[['Temperature', 'Min/Max temperature', 'Average temperature', 'Temperature SD',\n",
    "           'Octave intensities', 'Information gain', 'Principal components']].loc['Average per year'].sum()/ 7\n",
    "        avgw_list.append(avg_warnings)\n",
    "    k_dict['k = {}'.format(k)]['Total average'] = sum(avgw_list)/len(avgw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_dataframe = pd.DataFrame(k_dict).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k = 1.12</th>\n",
       "      <th>k = 1.27</th>\n",
       "      <th>k = 1.42</th>\n",
       "      <th>k = 1.6</th>\n",
       "      <th>k = 1.8</th>\n",
       "      <th>k = 2.03</th>\n",
       "      <th>k = 2.28</th>\n",
       "      <th>k = 2.57</th>\n",
       "      <th>k = 2.89</th>\n",
       "      <th>k = 3.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min/Max temperature</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average temperature</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature SD</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Octave intensities</th>\n",
       "      <td>14.5</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information gain</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Principal components</th>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total average</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      k = 1.12  k = 1.27  k = 1.42  k = 1.6  k = 1.8  \\\n",
       "Temperature                7.7       6.2       4.7      3.7      3.1   \n",
       "Min/Max temperature        3.6       2.3       1.8      1.4      1.2   \n",
       "Average temperature        2.4       2.0       1.5      1.0      1.0   \n",
       "Temperature SD             1.5       1.0       0.8      0.6      0.4   \n",
       "Octave intensities        14.5      12.6      11.1      9.5      8.3   \n",
       "Information gain           2.0       1.6       1.3      1.1      1.0   \n",
       "Principal components       3.3       2.3       1.7      1.3      1.1   \n",
       "Total average              5.0       4.0       3.3      2.7      2.3   \n",
       "\n",
       "                      k = 2.03  k = 2.28  k = 2.57  k = 2.89  k = 3.25  \n",
       "Temperature                2.4       2.1       1.8       1.5       1.2  \n",
       "Min/Max temperature        1.0       0.9       0.7       0.6       0.5  \n",
       "Average temperature        0.7       0.8       0.7       0.6       0.5  \n",
       "Temperature SD             0.3       0.3       0.2       0.1       0.1  \n",
       "Octave intensities         7.1       6.1       5.5       5.1       4.5  \n",
       "Information gain           0.8       0.7       0.6       0.5       0.4  \n",
       "Principal components       1.0       0.9       0.7       0.6       0.6  \n",
       "Total average              1.9       1.7       1.5       1.3       1.1  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(k_dataframe, 'k dataframe.png', max_cols=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('paramk125dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(warnings_dict_k125, f)\n",
    "        \n",
    "# with open('paramk125dict.pkl', 'rb') as f:\n",
    "#     dictie = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using \"EVALUATION LABELED CHANGEPOINT DATASETS\" to get a table with the number of days within which a warning was raised relative to the labeled changepoint for the combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [3,4,5,6,7,8,9,10,11,14,16,17,18,19]\n",
    "candidate_combinations = [(i, j) for i in candidates for j in candidates if i != j]\n",
    "chosen_combinations = random.choices(candidate_combinations, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chosen_combinations:\n",
    "    merge_datasets(path1='01 - Raw Data/Delivery 2 (enkel koelkast)/data_{}.xlsx'.format(i[0]), name1=i[0], index1=(-12*24*180-2000, -1), \n",
    "                   path2='01 - Raw Data/Delivery 2 (enkel koelkast)/data_{}.xlsx'.format(i[1]), name2=i[1], index2=(0, 12*24*180+2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_till_warning = dict()\n",
    "for i in chosen_combinations:\n",
    "    path = '01 - Raw Data/combinations/random combinations/data_{}_{}.xlsx'.format(i[0], i[1])\n",
    "    k_list = [2, 1.2, 1.125, 1.125, 2.3, 1.125, 1.2]\n",
    "    times_till_warning['{}, {}'.format(i[0], i[1])] = analyze_data(path, '{}, {}'.format(i[0], i[1]), lower=0, upper=100, N=(12*24), k_list=k_list, save='validation/dash val {}, {}'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "for times in times_till_warning:\n",
    "    for time in times_till_warning[times]:\n",
    "        times_till_warning[times][time] = int((times_till_warning[times][time].round(freq='D')+timedelta(days=1)).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col0,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col1,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col3,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col4,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col5,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col6,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col7,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col0,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col1,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col2,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col7,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col8,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col9,#T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col8{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >6, 3</th>        <th class=\"col_heading level0 col1\" >10, 5</th>        <th class=\"col_heading level0 col2\" >8, 5</th>        <th class=\"col_heading level0 col3\" >17, 9</th>        <th class=\"col_heading level0 col4\" >14, 9</th>        <th class=\"col_heading level0 col5\" >9, 18</th>        <th class=\"col_heading level0 col6\" >17, 16</th>        <th class=\"col_heading level0 col7\" >6, 5</th>        <th class=\"col_heading level0 col8\" >3, 16</th>        <th class=\"col_heading level0 col9\" >8, 19</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row0\" class=\"row_heading level0 row0\" >Octave intensities warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col2\" class=\"data row0 col2\" >2</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col7\" class=\"data row0 col7\" >2</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col8\" class=\"data row0 col8\" >2</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row0_col9\" class=\"data row0 col9\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row1\" class=\"row_heading level0 row1\" >Principal components warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col3\" class=\"data row1 col3\" >9</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col5\" class=\"data row1 col5\" >43</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col7\" class=\"data row1 col7\" >2</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col8\" class=\"data row1 col8\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row1_col9\" class=\"data row1 col9\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row2\" class=\"row_heading level0 row2\" >Temperature warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col0\" class=\"data row2 col0\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col1\" class=\"data row2 col1\" >4</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col2\" class=\"data row2 col2\" >31</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col3\" class=\"data row2 col3\" >9</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col4\" class=\"data row2 col4\" >9</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col5\" class=\"data row2 col5\" >102</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col6\" class=\"data row2 col6\" >3</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col7\" class=\"data row2 col7\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col8\" class=\"data row2 col8\" >1</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row2_col9\" class=\"data row2 col9\" >60</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row3\" class=\"row_heading level0 row3\" >Temperature Min/Max warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col0\" class=\"data row3 col0\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col1\" class=\"data row3 col1\" >4</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col2\" class=\"data row3 col2\" >31</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col3\" class=\"data row3 col3\" >9</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col4\" class=\"data row3 col4\" >34</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col5\" class=\"data row3 col5\" >3</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col6\" class=\"data row3 col6\" >33</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col7\" class=\"data row3 col7\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col8\" class=\"data row3 col8\" >3</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row3_col9\" class=\"data row3 col9\" >45</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row4\" class=\"row_heading level0 row4\" >Temperature average warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col0\" class=\"data row4 col0\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col1\" class=\"data row4 col1\" >31</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col2\" class=\"data row4 col2\" >13</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col3\" class=\"data row4 col3\" >134</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col4\" class=\"data row4 col4\" >108</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col5\" class=\"data row4 col5\" >32</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col6\" class=\"data row4 col6\" >87</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col7\" class=\"data row4 col7\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col8\" class=\"data row4 col8\" >87</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row4_col9\" class=\"data row4 col9\" >53</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row5\" class=\"row_heading level0 row5\" >Temperature SD warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col0\" class=\"data row5 col0\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col1\" class=\"data row5 col1\" >4</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col2\" class=\"data row5 col2\" >16</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col3\" class=\"data row5 col3\" >135</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col4\" class=\"data row5 col4\" >34</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col5\" class=\"data row5 col5\" >45</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col6\" class=\"data row5 col6\" >88</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col7\" class=\"data row5 col7\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col8\" class=\"data row5 col8\" >88</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row5_col9\" class=\"data row5 col9\" >44</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74level0_row6\" class=\"row_heading level0 row6\" >Information gain warning</th>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col0\" class=\"data row6 col0\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col1\" class=\"data row6 col1\" >5</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col2\" class=\"data row6 col2\" >113</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col3\" class=\"data row6 col3\" >9</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col4\" class=\"data row6 col4\" >135</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col5\" class=\"data row6 col5\" >45</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col6\" class=\"data row6 col6\" >88</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col7\" class=\"data row6 col7\" >999</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col8\" class=\"data row6 col8\" >88</td>\n",
       "                        <td id=\"T_04244e4c_f602_11ec_9a16_34f64bdcfd74row6_col9\" class=\"data row6 col9\" >44</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1769dfa4b80>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = pd.DataFrame(times_till_warning).fillna(999).astype(int)#.replace(404, '')\n",
    "times_highlighted = times.style.highlight_min(color = 'lightgreen', axis = 0)\n",
    "times_highlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(times_highlighted, 'warning times highlight.png', max_cols=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
